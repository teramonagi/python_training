{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "from gensim import corpora, models, similarities\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sample corpus and dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sample documents\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "              \"A survey of user opinion of computer system response time\",\n",
    "              \"The EPS user interface management system\",\n",
    "              \"System and human system engineering testing of EPS\",\n",
    "              \"Relation of user perceived response time to error measurement\",\n",
    "              \"The generation of random binary unordered trees\",\n",
    "              \"The intersection graph of paths in trees\",\n",
    "              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "              \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in', 'and', 'for', 'to', 'the', 'of', 'a'}\n"
     ]
    }
   ],
   "source": [
    "#define stop words\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "print(stoplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications'], ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'management', 'system'], ['system', 'human', 'system', 'engineering', 'testing', 'eps'], ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'], ['generation', 'random', 'binary', 'unordered', 'trees'], ['intersection', 'graph', 'paths', 'trees'], ['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering'], ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "#split documents into word list\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist] for document in documents]\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(35 unique tokens: ['perceived', 'trees', 'paths', 'quasi', 'iv']...)\n",
      "{'perceived': 17, 'trees': 22, 'paths': 28, 'quasi': 31, 'iv': 33, 'generation': 23, 'survey': 11, 'widths': 30, 'ordering': 29, 'user': 8, 'relation': 19, 'graph': 27, 'management': 14, 'system': 7, 'abc': 3, 'intersection': 26, 'interface': 1, 'human': 2, 'opinion': 10, 'computer': 4, 'lab': 6, 'minors': 32, 'engineering': 15, 'unordered': 21, 'binary': 25, 'measurement': 18, 'machine': 0, 'time': 9, 'random': 24, 'eps': 13, 'applications': 5, 'testing': 16, 'well': 34, 'response': 12, 'error': 20}\n"
     ]
    }
   ],
   "source": [
    "#define dictionary(word <--> id table)\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "print(dictionary)\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 1), (4, 1), (14, 1)]\n"
     ]
    }
   ],
   "source": [
    "#convert some document to (id, count) expression by dictionary\n",
    "print(dictionary.doc2bow(\"Human computer management\".lower().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)], [(4, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)], [(1, 1), (7, 1), (8, 1), (13, 1), (14, 1)], [(2, 1), (7, 2), (13, 1), (15, 1), (16, 1)], [(8, 1), (9, 1), (12, 1), (17, 1), (18, 1), (19, 1), (20, 1)], [(21, 1), (22, 1), (23, 1), (24, 1), (25, 1)], [(22, 1), (26, 1), (27, 1), (28, 1)], [(22, 1), (27, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1)], [(11, 1), (27, 1), (32, 1)]]\n"
     ]
    }
   ],
   "source": [
    "#Create corpus\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TF-IDF model for weighted vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.8251824121072071), (1, 0.5648663441460566)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define tf-idf model to convert vector spaces each other\n",
    "tfidf = models.TfidfModel(corpus) \n",
    "doc_bow = [(0, 1), (1, 1)]\n",
    "tfidf[doc_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.4301019571350565), (1, 0.2944198962221451), (2, 0.2944198962221451), (3, 0.4301019571350565), (4, 0.2944198962221451), (5, 0.4301019571350565), (6, 0.4301019571350565)]\n",
      "[(4, 0.3726494271826947), (7, 0.27219160459794917), (8, 0.27219160459794917), (9, 0.3726494271826947), (10, 0.5443832091958983), (11, 0.3726494271826947), (12, 0.3726494271826947)]\n",
      "[(1, 0.438482464916089), (7, 0.32027755044706185), (8, 0.32027755044706185), (13, 0.438482464916089), (14, 0.6405551008941237)]\n",
      "[(2, 0.3449874408519962), (7, 0.5039733231394895), (13, 0.3449874408519962), (15, 0.5039733231394895), (16, 0.5039733231394895)]\n",
      "[(8, 0.21953536176370683), (9, 0.30055933182961736), (12, 0.30055933182961736), (17, 0.43907072352741366), (18, 0.43907072352741366), (19, 0.43907072352741366), (20, 0.43907072352741366)]\n",
      "[(21, 0.48507125007266594), (22, 0.24253562503633297), (23, 0.48507125007266594), (24, 0.48507125007266594), (25, 0.48507125007266594)]\n",
      "[(22, 0.31622776601683794), (26, 0.6324555320336759), (27, 0.31622776601683794), (28, 0.6324555320336759)]\n",
      "[(22, 0.20466057569885868), (27, 0.20466057569885868), (29, 0.40932115139771735), (30, 0.40932115139771735), (31, 0.40932115139771735), (32, 0.2801947048062438), (33, 0.40932115139771735), (34, 0.40932115139771735)]\n",
      "[(11, 0.6282580468670046), (27, 0.45889394536615247), (32, 0.6282580468670046)]\n"
     ]
    }
   ],
   "source": [
    "#print converted vector for all corpus\n",
    "for x in tfidf[corpus]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic model(LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.061*system + 0.060*user + 0.060*trees + 0.060*survey + 0.060*graph + 0.046*computer + 0.046*interface + 0.035*response + 0.035*eps + 0.035*unordered')\n",
      "(1, '0.063*system + 0.052*human + 0.037*minors + 0.037*trees + 0.036*graph + 0.036*user + 0.036*time + 0.036*iv + 0.036*eps + 0.036*ordering')\n",
      "(2, '0.032*graph + 0.031*survey + 0.031*user + 0.031*system + 0.031*trees + 0.030*minors + 0.030*intersection + 0.029*time + 0.029*interface + 0.029*paths')\n",
      "[(0, 0.056904655603499645), (1, 0.89963036822034737), (2, 0.043464976176153025)]\n",
      "[(0, 0.91118353415640574), (1, 0.046230040182272072), (2, 0.042586425661322279)]\n",
      "[(0, 0.88120725743272066), (1, 0.062026445816163726), (2, 0.056766296751115553)]\n",
      "[(0, 0.052262479930604906), (1, 0.89911066481035962), (2, 0.048626855259035581)]\n",
      "[(0, 0.046355471420264978), (1, 0.91082265877905577), (2, 0.042821869800679264)]\n",
      "[(0, 0.8862337455431063), (1, 0.056774455085898269), (2, 0.0569917993709953)]\n",
      "[(0, 0.86195035587696844), (1, 0.069693068829925237), (2, 0.06835657529310632)]\n",
      "[(0, 0.041604044481430777), (1, 0.92031092489363808), (2, 0.038085030624931071)]\n",
      "[(0, 0.82259073817439787), (1, 0.09206867549066336), (2, 0.085340586334938795)]\n"
     ]
    }
   ],
   "source": [
    "lda = models.ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=3)\n",
    "for topic in lda.show_topics():\n",
    "    print(topic)\n",
    "for topics_per_document in lda[corpus]:\n",
    "    print(topics_per_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.056922226933856707), (1, 0.89961278283157864), (2, 0.043464990234564641)]\n"
     ]
    }
   ],
   "source": [
    "#first document is converted to LDA space \n",
    "print(lda[corpus[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similality calculation by LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.similarities.docsim:scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1.0), (1, 0.11569257), (2, 0.13581519), (3, 0.99997038), (4, 0.99992341), (5, 0.12950063), (6, 0.14657225), (7, 0.99981445), (8, 0.1776873)]\n"
     ]
    }
   ],
   "source": [
    "index = similarities.MatrixSimilarity(lda[corpus])\n",
    "sims = index[lda[corpus[0]]]\n",
    "#show similality including its own.\n",
    "print(list(enumerate(sims)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=35, size=100, alpha=0.025)\n",
      "computer 0.24336141347885132\n",
      "unordered 0.19552487134933472\n",
      "trees 0.19459959864616394\n",
      "time 0.16224011778831482\n",
      "intersection 0.1320515275001526\n",
      "perceived 0.12837675213813782\n",
      "quasi 0.12015747278928757\n",
      "opinion 0.11418915539979935\n",
      "survey 0.09854245185852051\n",
      "testing 0.09425602108240128\n"
     ]
    }
   ],
   "source": [
    "model = models.word2vec.Word2Vec(texts, size=100, min_count=1)\n",
    "print(model)\n",
    "out = model.most_similar(positive=[u'machine'])\n",
    "for x in out:\n",
    "    print(x[0],x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.088144269635882011"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similality between two words\n",
    "model.similarity('human', 'machine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('response', 0.2094278335571289)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# human + machine - management = ...?\n",
    "model.most_similar(positive=['human', 'machine'], negative=['management'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.03621560e-03,  -1.12776889e-03,  -2.70737638e-03,\n",
       "        -5.28433418e-04,   2.60211038e-03,   9.53729847e-04,\n",
       "         3.83250951e-03,  -1.87926169e-04,   1.37907965e-03,\n",
       "         4.53122426e-03,  -3.99733381e-03,   3.74906725e-04,\n",
       "         1.51365087e-03,   2.42908625e-03,   8.26373172e-04,\n",
       "        -4.08146158e-03,   3.85995349e-03,   1.98068633e-03,\n",
       "        -9.78420838e-04,  -4.98752249e-03,   4.76452842e-04,\n",
       "        -6.89192035e-04,   9.50184476e-05,   4.55490453e-03,\n",
       "        -4.83759353e-03,  -2.50132009e-03,  -3.38290608e-03,\n",
       "        -1.84357655e-03,  -2.84379092e-03,  -1.23974343e-03,\n",
       "        -1.71634916e-03,   4.69436450e-03,  -4.46483353e-03,\n",
       "        -4.72780969e-03,   3.52653768e-03,  -4.06282907e-03,\n",
       "         3.09269712e-03,   1.19773776e-03,   8.99195904e-04,\n",
       "        -3.89312534e-03,  -2.15449394e-03,   4.85087512e-04,\n",
       "        -1.38260715e-04,   3.29889753e-03,  -3.44559969e-03,\n",
       "        -3.99467535e-04,  -7.12820794e-04,  -4.72263526e-03,\n",
       "        -4.13687946e-03,   2.91077653e-03,  -3.65466438e-03,\n",
       "        -3.08239530e-03,  -1.18643642e-04,   4.09531081e-03,\n",
       "        -7.17996794e-04,  -4.38976800e-04,  -1.27351633e-03,\n",
       "        -3.42496834e-03,  -1.22235797e-03,  -1.86042220e-03,\n",
       "         8.13887164e-04,  -3.59656685e-03,  -2.19820213e-04,\n",
       "        -4.86247102e-03,   4.65844851e-03,  -3.47465696e-03,\n",
       "        -2.34484003e-04,  -3.56429000e-03,   1.99037301e-03,\n",
       "        -4.26122639e-03,  -9.44417843e-04,  -3.42582818e-03,\n",
       "        -2.05500913e-03,  -1.90540811e-03,  -7.59385512e-05,\n",
       "         4.14848188e-03,  -1.10159104e-03,  -3.36546567e-03,\n",
       "        -8.84763314e-04,  -1.41662394e-03,  -4.99944296e-03,\n",
       "         3.82761355e-03,  -7.57969683e-04,  -4.88217268e-03,\n",
       "         1.66904682e-03,   1.12542708e-03,  -2.53356015e-03,\n",
       "        -3.88955628e-03,   2.05548387e-03,   2.38289288e-03,\n",
       "         2.26046494e-03,   9.92155867e-04,   3.97788407e-03,\n",
       "         4.76853782e-03,  -1.85964361e-03,  -5.38722554e-04,\n",
       "        -1.54510804e-03,   6.37433724e-04,   2.41537369e-03,\n",
       "         2.28356640e-03], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show vector expression of a word\n",
    "model['human']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.21747982e-03,  -5.98347164e-04,  -7.44400895e-04,\n",
       "        -4.24063939e-04,   1.08058746e-04,  -7.97799148e-04,\n",
       "         6.76415511e-04,  -4.90673003e-04,   2.94549129e-04,\n",
       "         8.47728734e-05,  -2.05539051e-03,  -6.16764650e-04,\n",
       "         1.00845157e-03,  -7.69111037e-04,   2.21019913e-03,\n",
       "        -2.06974358e-03,  -2.60475295e-04,  -4.84288001e-04,\n",
       "         3.15664045e-04,  -4.33850830e-04,  -1.36917713e-03,\n",
       "        -2.42086662e-05,  -6.14502351e-04,   1.42709631e-03,\n",
       "        -1.21736713e-03,   2.66548246e-04,  -1.97036425e-04,\n",
       "        -1.54024560e-03,  -1.00586086e-03,  -2.87082348e-05,\n",
       "        -1.44869206e-03,   3.38991318e-04,  -2.33746460e-03,\n",
       "        -5.71915763e-04,  -5.00007358e-04,  -3.71419446e-04,\n",
       "         2.40033507e-04,   1.43597357e-03,  -4.65652905e-04,\n",
       "        -1.29254453e-03,  -9.98286181e-04,   9.67176748e-04,\n",
       "         1.74276181e-03,  -3.53550931e-05,  -8.21346301e-04,\n",
       "        -1.77060149e-03,   8.81072890e-04,   1.40109376e-04,\n",
       "         4.32525005e-04,  -1.61647004e-05,   3.55752971e-04,\n",
       "        -2.19552807e-04,   1.15174067e-03,   6.54711213e-04,\n",
       "        -4.14286769e-04,  -1.29823748e-03,  -1.43945205e-03,\n",
       "        -1.92757201e-04,   5.61934488e-04,  -2.65546003e-03,\n",
       "         5.05261705e-04,   3.25888599e-04,   1.42958586e-03,\n",
       "        -5.84729423e-04,  -1.72825321e-03,   7.02509598e-04,\n",
       "        -1.70450169e-03,  -3.03346402e-04,   1.02051557e-03,\n",
       "        -1.11165503e-03,   8.47373449e-04,  -3.19554645e-04,\n",
       "        -5.79323736e-04,  -1.28575542e-03,  -1.50015764e-03,\n",
       "         2.37075798e-03,  -3.01368302e-04,   5.86779148e-04,\n",
       "        -2.02310132e-03,   3.05019948e-03,   3.05430993e-04,\n",
       "        -4.94009932e-04,  -2.18850118e-03,  -1.26015453e-03,\n",
       "         1.77680305e-03,   1.46396493e-03,  -1.55065954e-03,\n",
       "        -1.71955919e-03,   9.08211150e-05,   3.02041124e-04,\n",
       "         1.11539732e-03,   1.90507679e-03,   3.35876219e-04,\n",
       "         9.98714822e-04,   2.08138095e-04,  -1.07659365e-03,\n",
       "         4.05389030e-04,   3.99776327e-04,  -2.58092745e-03,\n",
       "         6.05424226e-04], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector expression of text(just simple average of each words...)\n",
    "np.mean(model[texts[0]], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I'm not sure why this kinds of classes are implemented in the package...\n",
    "class LabeledListSentence(object):\n",
    "    def __init__(self, words_list):\n",
    "        self.words_list = words_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        t = [t for t in self]\n",
    "        return t[index]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for i, words in enumerate(self.words_list):\n",
    "            yield models.doc2vec.LabeledSentence(words, ['text_{0}'.format(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1.0), (3, 0.07125711441040039), (2, 0.015766317024827003), (8, -0.00950068049132824), (4, -0.021924331784248352), (7, -0.03319110721349716), (5, -0.03922884911298752), (6, -0.04244283586740494), (0, -0.07505106180906296)]\n"
     ]
    }
   ],
   "source": [
    "labeled_texts = LabeledListSentence(texts)\n",
    "model = models.doc2vec.Doc2Vec(labeled_texts, min_count=1, alpha=0.025, min_alpha=0.025)\n",
    "print(model.docvecs.most_similar([model.docvecs[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful references\n",
    "- https://radimrehurek.com/gensim/index.html\n",
    "- http://hivecolor.com/id/58\n",
    "- http://qiita.com/okappy/items/e16639178ba85edfee72\n",
    "- http://qiita.com/yasunori/items/31a23eb259482e4824e2\n",
    "- http://qiita.com/shima_x/items/196e8d823412e45680e9\n",
    "- http://tjo.hatenablog.com/entry/2014/06/19/233949\n",
    "- http://rare-technologies.com/word2vec-tutorial/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
