{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sample corpus and dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "#sample documents\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "              \"A survey of user opinion of computer system response time\",\n",
    "              \"The EPS user interface management system\",\n",
    "              \"System and human system engineering testing of EPS\",\n",
    "              \"Relation of user perceived response time to error measurement\",\n",
    "              \"The generation of random binary unordered trees\",\n",
    "              \"The intersection graph of paths in trees\",\n",
    "              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "              \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and', 'for', 'a', 'of', 'the', 'in', 'to'}\n"
     ]
    }
   ],
   "source": [
    "#define stop words\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "print(stoplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications'], ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'management', 'system'], ['system', 'human', 'system', 'engineering', 'testing', 'eps'], ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'], ['generation', 'random', 'binary', 'unordered', 'trees'], ['intersection', 'graph', 'paths', 'trees'], ['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering'], ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "#split documents into word list\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist] for document in documents]\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(35 unique tokens: ['minors', 'trees', 'paths', 'human', 'binary']...)\n",
      "{'minors': 34, 'trees': 24, 'paths': 26, 'human': 1, 'binary': 22, 'random': 21, 'opinion': 8, 'user': 9, 'testing': 16, 'management': 14, 'measurement': 17, 'computer': 0, 'machine': 2, 'relation': 20, 'lab': 4, 'iv': 33, 'survey': 12, 'generation': 25, 'well': 31, 'time': 7, 'widths': 29, 'quasi': 30, 'abc': 3, 'error': 19, 'ordering': 32, 'graph': 28, 'response': 10, 'perceived': 18, 'intersection': 27, 'engineering': 15, 'eps': 13, 'unordered': 23, 'applications': 5, 'system': 11, 'interface': 6}\n"
     ]
    }
   ],
   "source": [
    "#define dictionary(word <--> id table)\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "print(dictionary)\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (14, 1)]\n"
     ]
    }
   ],
   "source": [
    "#convert some document to (id, count) expression by dictionary\n",
    "print(dictionary.doc2bow(\"Human computer management\".lower().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)], [(0, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)], [(6, 1), (9, 1), (11, 1), (13, 1), (14, 1)], [(1, 1), (11, 2), (13, 1), (15, 1), (16, 1)], [(7, 1), (9, 1), (10, 1), (17, 1), (18, 1), (19, 1), (20, 1)], [(21, 1), (22, 1), (23, 1), (24, 1), (25, 1)], [(24, 1), (26, 1), (27, 1), (28, 1)], [(24, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1)], [(12, 1), (28, 1), (34, 1)]]\n"
     ]
    }
   ],
   "source": [
    "#Create corpus\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TF-IDF model for weighted vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.7071067811865476), (1, 0.7071067811865476)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define tf-idf model to convert vector spaces each other\n",
    "tfidf = models.TfidfModel(corpus) \n",
    "doc_bow = [(0, 1), (1, 1)]\n",
    "tfidf[doc_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.2944198962221451), (1, 0.2944198962221451), (2, 0.4301019571350565), (3, 0.4301019571350565), (4, 0.4301019571350565), (5, 0.4301019571350565), (6, 0.2944198962221451)]\n",
      "[(0, 0.3726494271826947), (7, 0.3726494271826947), (8, 0.5443832091958983), (9, 0.27219160459794917), (10, 0.3726494271826947), (11, 0.27219160459794917), (12, 0.3726494271826947)]\n",
      "[(6, 0.438482464916089), (9, 0.32027755044706185), (11, 0.32027755044706185), (13, 0.438482464916089), (14, 0.6405551008941237)]\n",
      "[(1, 0.3449874408519962), (11, 0.5039733231394895), (13, 0.3449874408519962), (15, 0.5039733231394895), (16, 0.5039733231394895)]\n",
      "[(7, 0.30055933182961736), (9, 0.21953536176370683), (10, 0.30055933182961736), (17, 0.43907072352741366), (18, 0.43907072352741366), (19, 0.43907072352741366), (20, 0.43907072352741366)]\n",
      "[(21, 0.48507125007266594), (22, 0.48507125007266594), (23, 0.48507125007266594), (24, 0.24253562503633297), (25, 0.48507125007266594)]\n",
      "[(24, 0.31622776601683794), (26, 0.6324555320336759), (27, 0.6324555320336759), (28, 0.31622776601683794)]\n",
      "[(24, 0.20466057569885868), (28, 0.20466057569885868), (29, 0.40932115139771735), (30, 0.40932115139771735), (31, 0.40932115139771735), (32, 0.40932115139771735), (33, 0.40932115139771735), (34, 0.2801947048062438)]\n",
      "[(12, 0.6282580468670046), (28, 0.45889394536615247), (34, 0.6282580468670046)]\n"
     ]
    }
   ],
   "source": [
    "#print converted vector for all corpus\n",
    "for x in tfidf[corpus]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic model(LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.062*system + 0.061*graph + 0.058*human + 0.037*trees + 0.037*minors + 0.036*eps + 0.036*time + 0.035*response + 0.035*measurement + 0.035*perceived')\n",
      "(1, '0.087*trees + 0.051*graph + 0.050*random + 0.050*generation + 0.050*unordered + 0.050*binary + 0.049*ordering + 0.049*iv + 0.049*minors + 0.049*quasi')\n",
      "(2, '0.097*user + 0.097*system + 0.056*survey + 0.055*computer + 0.055*response + 0.055*interface + 0.055*eps + 0.055*time + 0.054*management + 0.054*opinion')\n",
      "[(0, 0.90902847546723375), (1, 0.043984891726608355), (2, 0.046986632806157884)]\n",
      "[(0, 0.045190777308922694), (1, 0.04204965574509055), (2, 0.9127595669459867)]\n",
      "[(0, 0.059481657183272606), (1, 0.056190244784453912), (2, 0.88432809803227352)]\n",
      "[(0, 0.89507739984606638), (1, 0.048159158978324706), (2, 0.056763441175608879)]\n",
      "[(0, 0.90476058228775469), (1, 0.042191285162119278), (2, 0.053048132550126123)]\n",
      "[(0, 0.056394704603308511), (1, 0.88756012105227844), (2, 0.056045174344413085)]\n",
      "[(0, 0.85026168187101059), (1, 0.082190066308111029), (2, 0.067548251820878577)]\n",
      "[(0, 0.039221238817336981), (1, 0.92339923027019266), (2, 0.037379530912470253)]\n",
      "[(0, 0.81039065741143923), (1, 0.096077989956445314), (2, 0.093531352632115455)]\n"
     ]
    }
   ],
   "source": [
    "lda = models.ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=3)\n",
    "for topic in lda.show_topics():\n",
    "    print(topic)\n",
    "for topics_per_document in lda[corpus]:\n",
    "    print(topics_per_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.9090002653953051), (1, 0.043985250236135455), (2, 0.047014484368559449)]\n"
     ]
    }
   ],
   "source": [
    "#first document is converted to LDA space \n",
    "print(lda[corpus[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similality calculation by LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.similarities.docsim:scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1.0), (1, 0.1029003), (2, 0.12119333), (3, 0.99991703), (4, 0.99997473), (5, 0.11444242), (6, 0.99847388), (7, 0.092569277), (8, 0.99564171)]\n"
     ]
    }
   ],
   "source": [
    "index = similarities.MatrixSimilarity(lda[corpus])\n",
    "sims = index[lda[corpus[0]]]\n",
    "#show similality including its own.\n",
    "print(list(enumerate(sims)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=35, size=100, alpha=0.025)\n",
      "perceived 0.257527232170105\n",
      "management 0.20598620176315308\n",
      "testing 0.14812245965003967\n",
      "unordered 0.14332260191440582\n",
      "generation 0.1272101253271103\n",
      "minors 0.1088174507021904\n",
      "engineering 0.10216177999973297\n",
      "random 0.08155420422554016\n",
      "trees 0.06890177726745605\n",
      "response 0.06308461725711823\n"
     ]
    }
   ],
   "source": [
    "model = models.word2vec.Word2Vec(texts, size=100, min_count=1)\n",
    "print(model)\n",
    "out = model.most_similar(positive=[u'machine'])\n",
    "for x in out:\n",
    "    print(x[0],x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.061809501778046678"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similality between two words\n",
    "model.similarity('human', 'machine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('generation', 0.1547522246837616)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['human', 'machine'], negative=['management'], topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [TODO]Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful references\n",
    "- https://radimrehurek.com/gensim/index.html\n",
    "- http://hivecolor.com/id/58\n",
    "- http://qiita.com/okappy/items/e16639178ba85edfee72\n",
    "- http://qiita.com/yasunori/items/31a23eb259482e4824e2\n",
    "- http://tjo.hatenablog.com/entry/2014/06/19/233949\n",
    "- http://rare-technologies.com/word2vec-tutorial/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
